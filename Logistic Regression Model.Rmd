---
title: "Using A Logistic Regression Model To Predict Survivors Of The Titanic Disaster"
author: "Jarred Petersen"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

During this project, I will train logistic regression model to predict whether a passenger will survive the sinking of the Titanic based on the sex, gender, class, ticket fare, and family size of the passenger in question. This project will display multiple data analytic skills such as data cleaning, data visualization, use of machine learning models, and understanding and interpreting its output. Please find the link to the csv file used below:

*Link to csv*

I will be using the csv file found on the following link
https://www.kaggle.com/code/alexisbcook/titanic-tutorial/notebook

### Load Packages

```{r}
library(readr)       # load readr package
library(tidyverse)   # load tidyverse package
library(ggplot2)     # load ggplot2 package
library(dplyr)       # load dplyr package
library(mlr)         # load the mlr package
```

### Read in Data

Firstly, I will load in the "train.csv" file. As the name suggests, this will be used for training the model.

```{r}
titanic <- read_csv("train.csv") # read in data set as titanic data frame

titanicTib <- as_tibble(titanic) # format data set as tibble
```

### Exploring Data set

First step of data analysis is to explore the data set to understand what you are working with, and what cleaning needs to be done before I start analyzing the data.

```{r}
dim(titanicTib)  # View dimensions of data set
```

Viewing the dimension of the data set, we have 891 observations and 12 variables.

```{r}
str(titanicTib) # View structure of the data set
```

The str() function shows us the structure of the data set. We can see the 12 variables, the data type of the variables, and some of the values.
The 12 values we are working with are passenger id, survived, pclass (passenger class), name, sex, age, Sibsp (Number of siblings/spouses aboard), parch (number of parents/children aboard), ticket, fare, cabin, and embarked. 
For this project, I will be focusing on age, sex, family size (SibSp + Parch), fare, and passenger class. I can already see some cleaning that needs to be done which I will go into later.

```{r}
head(titanicTib) # view first 6 rows
tail(titanicTib) # view last 6 rows
```

### Cleaning Data set

Now that we have explored the data set, I will begin cleaning the data.
In order to clean this data for analysis, I will create a new variable called "FamSize" which will be "SibSp" + "Parch" variables. I will also need to change "sex", "survived" and "pclass" variables to factors. In addition, I will only be working with survived, pclass, sex, age, famsize and fare variables. Therefore, I will create a smaller data object with these variables. 

```{r}
titanic1 <- titanicTib %>%                              
  mutate(FamSize = SibSp + Parch)                           # Create FamSize variable by adding SibSp + Parch

titanic_clean <- titanic1 %>%                             
  select("Survived",                                        # select the following variables 
         "Pclass",                                        
         "Sex",                                           
         "Age",                                           
         "FamSize",                                       
         "Fare") %>%                                     
  mutate_at(c("Survived", "Pclass", "Sex"), as.factor)      #convert Survived, pclass, sex, title to factors
```


### Visualizing Data Set

Now that I have a clean data set, I will create a few visualizations using ggplot to show the relationship of variables and their impact on whether the passenger survived the sinking of the Titanic.

```{r}
titanic_clean %>% 
  ggplot(aes(Survived,                                                       # Plotting Survived variable on X axis, count will be on Y
             fill = Sex))+                                                   # fill bar color by "Sex" variable
  geom_bar()+                                                                # Creating a bar plot 
  facet_grid(~ Pclass)+                                                      # Using facet_grid to place 3 plots for each class 
  theme_minimal()+                                                           # Using minimal theme
  labs(title = "Survival Of Male & Female Passengers In Each Class",         # set labels for main title, axis and legend
       x = "Survival",                              
       y = "Count")
```

Above we have the graph that shows us the count of male and female passengers that survived and didn't survive in each of the three classes.
One conclusion we can quickly make is that in each of the three classes, the majority of survivors were female passengers. We can also see that 3rd class passengers were far less likely to survive than 1st and 2nd class passengers. Of course we have to take into account that there were a lot more passengers in 3rd class compared to 1st and 2nd which will have an impact on our conclusions. To combat this, we could look at percentages of passengers that survived in each class rather than looking at count of passengers.


```{r}
gender <- titanic_clean %>%                       #create data object for gender visualization
  group_by(Pclass, Sex, Survived) %>%             #group by sex and survived variables
  summarise(Count = n()) %>%                      #Count values using summarize function
  mutate(Percentage = round(Count/sum(Count)*100))#add percentage column - Count/sum count*100 rounded

gender %>% 
  ggplot(aes(Survived, Percentage,                                           # Plotting Survived variable on X axis, count will be on Y
             fill = Sex))+                                                   # fill bar color by "Sex" variable
  geom_col(position = "fill")+                                               # Creating a bar plot showing proportions
  scale_y_continuous(labels = scales::percent)+                              # Scale y axis to show percentage
  facet_grid(~ Pclass)+                                                      # Using facet_grid to place 3 plots for each class 
  theme_minimal()+                                                           # Using minimal theme
  labs(title = "Survival Of Male & Female Passengers In Each Class",         # set labels for main title, axis and legend
       x = "Survival",                              
       y = "Count")
```

When we compare the percentages of female and male passengers in each class that survived/did not survive the sinking of the Titanic, we can conclude that females in 1st and 2nd class were more likely to survive than female passengers in 3rd class. It also shows that male passengers were far less likely to survive than female passengers.

Next, I want to create a histogram to explore the survival passengers by age. 

```{r}
titanic_clean %>% 
  ggplot(aes(Age,                                       # Plot age on x
             fill = Survived))+                         # fill color of bars by survived variable
  geom_histogram()+                                     # plot a histogram
  theme_minimal()+                                      # Use minimal theme
  facet_grid(~Sex)+                                     # Facet using sex variable
  labs(title = "Survival Of Passengers By Age",         # set labels for main title, axis and legend
       x = "Survival",                              
       y = "Count")
```

When we create the histogram, R gives us a warning that there are NA values in the age variable. for this visualization, I will ignore NA values. However, when I begin building the model, I will impute the mean age into the NA values.

When we look at the distribution of data across ages for male and female passengers that survived/ did not survive the sinking of the Titanic, we can conclude the following:
1) In female passengers, the survival of passengers across all ages was pretty high. 
2) In male passengers, very young babies and males age 20-32 had the best survival rate. However, the chances of survival was pretty low across all ages.


### Builing The Logistic Regression Model 

I will now build my logistic regression model, and train it using the training data we have been working with so far. 

Firstly, I want to check for any NA values in the data set as these may impact the model.

```{r}
sum(is.na(titanic_clean))   # View how many NA values are present in the data set.
```

There are 177 NA values present, which are present in the "Age" variable which we saw while creating our histogram. In order to deal with these NA values, I will impute the mean of the "age" variable using the impute() function.

```{r}
imp <- impute(titanic_clean, cols = list(Age = imputeMean()))  # Use mean of age variable to impute missing values

sum(is.na(imp$data$Age))                                       #view NA values in age variable in imputed object
```

Now that there are no NA values present in the data set, we can build the logistic regression model. We will also be using k-fold cross validation to cross validate our logistic regression model. 

```{r}
titanicTask <- makeClassifTask(data = imp$data, target = "Survived")  # set classification task using imp data set. target variable = survived
logReg <- makeLearner("classif.logreg", predict.type = "prob")        # model learner = logistic regression. Use probability for prediction
logRegModel <- train(logReg, titanicTask)                             

logRegWrapper <- makeImputeWrapper("classif.logreg",
                                   cols = list(Age = imputeMean()))


kFold <- makeResampleDesc(method = "RepCV", folds = 10, reps = 50,    # Create k-fold CV with 10 folds, 50 reps 
                          stratify = TRUE)                            # and stratified resampling

logRegwithImpute <- resample(logRegWrapper, titanicTask,              # Run model 
                             resampling = kFold,                      # using k-fold CV
                             measures = list(acc, fpr, fnr))          # Return accuracy, false positive rate, and false negative rate
```

The performance measures show the following
- The mean accuracy was 79.6%. This means that 79.6% of cases were correctly classified.
- The mean false positive rate was 29.9%. This means that it incorrectly classified 29.9% of passengers who died as having survived.
- The false negative rate was 14%. This means that of passengers who survived as having died.
Although the accuracy of the model is only 79.6%, the false negative rate is pretty low which is good for the context of this model as the number of positive cases (passenger surviving the sinking) is rare. As positive cases are rare, it is important that our model doesn't wrong classify positive cases as negative. 

Now that we have viewed our models performance measures, we want to extract our model parameters for interpretation. Extracting these parameters will show us the y-intercept, and the slope for each of the predictors.

```{r}
logRegModelData <- getLearnerModel(logRegModel)                       # Turn model into model object to view parameters

coef(logRegModelData)                                                 # View model parameters
```

To make these parameters easier to interpert, we will convert them into odds ratios, as shown below:

```{r}
exp(cbind(Odds_Ratio = coef(logRegModelData), confint(logRegModelData))) #convert model parameters into odds ratios
```

When we look at the odds ratio, we notice that most of these values are below 1. Odds ratio below 1 mean those variables are less likely to survive the Titanic disaster. If we divide 1 by the odds ratio of the particular variable, it is easier to interpret. 
For example,
1) Male passenger = 1/0.06 = 16.7. This means that male passengers were 16.7% less likely to survive than female passengers.
2) 2nd class passengers = 1/0.38 = 2.7. This means that 2nd class passengers were 2.7% less likely to survive than 1st class passengers.
3) 3rd class passengers = 1/0.12 = 8.4. This means that 3rd class passengers were 8.4% less likely to survive than 1st class passengers.
4) Family size = 1/0.78 = 1.3. This means that for every additional family member, the passenger was 1.3% less likely to survive.

The 95% confidence values in the fare variable includes a 1, therefore the odds are equal. This means that it is possible that the fare variable has no impact of the survival of the passenger


### Using data from test.csv to make prediction

Finally, we will use the the model to make predictions on the "test.csv" file.
This data will also need a little bit of cleaning, similar to what we did with the training data, before we put it through our model.

```{r}
test <- read.csv("test.csv")                                  # Read in test.csv file

test_clean <- test %>%                                        # Clean test data
  mutate_at(.vars = c("Sex", "Pclass"), .funs = factor) %>%   # Change sex and pclass variable to factors
  mutate(FamSize = SibSp + Parch) %>%                         # Create FamSize variable by combining SibSp and Parch variables
  select(Pclass, Sex, Age, Fare, FamSize)                     # Select pclass, sex, age, fare and FamSize variables
```

Now that the data is cleaned, we can use the model to make predictions on this new data using the predict() function.

```{r}
test_results <- predict(logRegModel, newdata = test_clean) # use model to make predictions on test data

as.tibble(test_results)                                    # Make test_results object a tibble

view(test_results)                                         # view test_result predictions
```

We can see that our model has made predictions on whether each of the 418 passengers in our test data survived the sinking of the Titanic.

This concludes my Rmarkdown project. 





